\documentclass{dithesis}
\usepackage{mathspec}
\usepackage{xunicode}
\usepackage{enumitem}
\usepackage{ifthen}

% Math
\usepackage{amsfonts}

% Tikz
\usepackage{smartdiagram}
\usepackage{tikz}
\usetikzlibrary{arrows,mindmap,trees,fit,backgrounds,decorations.pathreplacing}

% Colors
\usepackage{xcolor}
\definecolor{num}{HTML}{FF7506}
\definecolor{myrd}{HTML}{B60005}
\definecolor{mybl}{HTML}{00706C}\definecolor{mygr}{HTML}{079500}
\definecolor{mybr}{HTML}{B85200}
\colorlet{myye}{yellow!30}

% Images
\usepackage{multicol}
\graphicspath{ {images/} }

% Code
\usepackage{minted}

% URL
\usepackage{url}

% TODO notes
\usepackage[colorinlistoftodos,prependcaption]{todonotes}

\setallmainfonts[Mapping=tex-text]{Arial}
\setallsansfonts[Mapping=tex-text]{Arial}
\setallmonofonts[Mapping=tex-text]{Arial}

\renewcommand{\university}{National and Kapodistrian University of Athens}
\renewcommand{\school}{Faculty of Exact Sciences}
\renewcommand{\department}{Department of Informatics and Telecommunications}
\renewcommand{\thesisplace}{Athens}
\renewcommand{\thesisdate}{April 2016}
\renewcommand{\thesislabel}{Bachelor Thesis}
\renewcommand{\supervisorlabel}{Supervisors}
\renewcommand{\idlabel}{Α.Μ.}

\renewcommand{\contentsname}{Contents}
\renewcommand{\listfigurename}{List of Figures\vspace{5 mm}}
\renewcommand{\figurename}{Figure}
\renewcommand{\listtablename}{List of Tables\vspace{5 mm}}
\renewcommand{\tablename}{Table}
\renewcommand{\refname}{References}

\begin{document}

\input{MACROS.tex}

\thesistitle{RHEA: A Reactive, Heterogeneous, Extensible and Abstract Framework for Dataflow Programming}
\thesisauthor{Orestis Melkonian}{1115201000128}
\supervisor{Panos Rondogiannis}{Professor EKPA}
\supervisor{Angelos Charalambidis}{Researcher NCSR}
\maketitle

\begin{thesisabstract}[Abstract]

The dataflow computational model enables writing highly parallel programs, which will be deployed on a heterogeneous network, in a concise and readable way. The main advantage is the fact that the system can be conceptually separated into several independent components that can be run in parallel and deployed on different machines. Therefore, concurrency and distribution is implicit and little or no responsibility is given to the programmer. The framework proposed in this thesis constitutes the underlying system that make this style of programming possible in JVM-based languages (e.g. Java, Scala, Closure), while at the same time making it easy to integrate other technologies that rely on the PubSub model, in order to move away from imperative languages and enter a higher level of abstraction. Particular emphasis was put on three domains, namely \textit{Big Data}, \textit{Robotics} and \textit{IoT}. A detailed specification of the framework's characteristics and capabilities is given, followed by some robotic applications that demonstrate these attributes. Finally, related work and recent technologies are discussed.

\thesiskeywords
{Subject Area}{Programming Languages}
{Keywords}
	{dataflow programming}
	{FRP}
	{stream processing}
	{distributed systems}
	{declarative languages, implicit concurrency, node placement}
\end{thesisabstract}

\begin{thesisdedication}
"τὰ όντα ιέναι τε πάντα καὶ μένειν ουδέν" \\
(all entities move and nothing remains still) \\
- Heraclitus
\end{thesisdedication}

\begin{thesisacknowledgments}[Acknowledgements]

I would like to thank Angelos Charalambidis for his immensely helpful supervision and guidance throughout the whole period of 6 months that I was present in NCSR. 

I would also like to thank Professor Panos Randogiannis for being a major influence in my current research interests through the undergraduate courses "Theory of Computation" and "Principles of Programming Languages", where I was introduced to a much more declarative way of programming and started appreciating mathematical sensibility in computing.

\end{thesisacknowledgments}

\tableofcontents
\listoffigures

\begin{thesisprologue}[Prologue]

This bachelor thesis is the continuation of my internship at the National Centre for Scientific Research "Demokritos", particularly in the Software and Knowledge Engineering Laboratory (SKEL). 

The main task I was assigned was the implementation of a framework for robot programming using a dataflow approach. During that internship, I came to realize that my work could be easily generalized to cover a much broader application area than just robot software. 

The name of the framework stems from the ancient Greek Titaness Rhea(\textit{Ρέα}), daughter of earth goddess Gaia(\textit{Γαία}) and sky god Uranus(\textit{Ουρανός}) and etymologically derives from the verb \textit{ρέω}(to flow).

\end{thesisprologue}

\thesissection{Introduction}

\thesissubsection{Main concept}

My main contribution is the design and implementation of a framework for dataflow programming to be deployed anywhere, ranging from low-performance robots and sensors to clusters of computer and even the Cloud. 

The main idea is to provide the programmer with a different execution model, the dataflow model, which allows for a more abstract way of thinking and has the advantage of exposing opportunities for parallelism (amongst CPU cores) and distribution (amongst computational machines), which can then be automatically realised by the "intelligent" underlying system. 

Therefore, the programmer will be able to utilize available computational resources without any effort, while at the same time reducing development time/cost and maintaining a much cleaner and easier-to-refactor software system. Resource utilization may appear in the form of faster execution or more robust error-handling. 

\todo[inline,linecolor=red,backgroundcolor=red!25,bordercolor=red]{Chain of Gain. Introduce running example?}

\thesissubsection{Motivation}

\thesissubsubsection{Declarative languages}

Software is becoming increasingly more complex each year, as computing capabilities are strengthened and user needs become more and more demanding. Thus the need for higher abstraction becomes imperative, as it provides a more structured, easier to debug and maintainable way of developing software. In other words, abstraction in computer science acts as a mean to overcome complexity. 

In programming languages, the level of the aforementioned abstraction is measured regarding the amount of low-level details a programmer has to specify. Therefore, languages can be divided in two categories: the imperative ones, in which the programmer specifies what needs to be done and how to do it, and the declarative ones, where the programmer only specifies what needs to be done and rely on the underlying compiler/interpreter to produce the exact commands that will realize the desired behaviour. The most well-known declarative programming paradigms are functional and logic programming, each providing higher abstraction in different aspects. My approach was greatly influenced by the functional paradigm.

\thesissubsubsection{Data versus Computation}			

A common problem in heterogeneous systems is that different representations of the same entities/data-types coexist in the same software and, as a consequence, pure computational tasks are intermingled with data-converting tasks. This makes the code less readable and harder to maintain and understand. In the dataflow execution model, where the program is modelled as directed graph of data flowing between operations, there is a clear separation of these two aspects as data (edges) are completely decoupled from computation (nodes). This motivation is strengthened even more, when cross-machine communication is included, and apart from converting data from one representation to another, serialization(i.e. conversion to bytes) is also mandatory.

\thesissubsubsection{Dataflows in Robotics}

In control theory, which is the main background theory used in robotics, most architectures and/or algorithms are represented as dataflow diagrams for the sake of clarity and intuition. Translating these diagrams into common "imperative" software is not an easy task and is usually the source of bugs. Thus, having a dataflow execution model will nullify the need for such a translation.

Specifically, most robotic applications follow the \textit{Robot Perception Architecture (RPA)}, where inputs to system are the robot's sensors, which are then processed by a dataflow graph, whose output is given as commands to the robot actuators.

Moreover, robotics typically involve several different robotic systems, whose combination is even more challenging. If each individual system is represented as a dataflow graph, composing them together is as trivial as connecting inputs with outputs, which is not the case in a traditional architecture, which is not component-based.

\thesissubsubsection{Dataflows in Big Data}

Another reason for following a dataflow approach is the attention that it recently has drawn in the \textit{Big Data} field. As data size is growing exponentially and distribution is not a luxury but a necessity, a more scalable and decentralized architecture was destined to be examined in more depth. As we will discuss in the \textit{Related Work} chapter, there are many recent frameworks that became famous for their scalability due to the fact that they rely on a dataflow approach.

\thesissubsection{Structure of thesis}

There are nine chapters which compose this thesis: \textit{Introduction, Background, Approach, Implementation, Applications, Related Work, Future Work, Conclusions}.

\textit{Background} introduces the reader to basic background knowledge, necessary for complete comprehension.

\textit{Approach} presents the main characteristics of my approach.

\textit{Implementation} gives a more detailed specification of the framework.

\textit{Applications} present some use-cases, ranging from general mathematical problems to real-life robot scenarios.

\textit{Related Work} discusses relevant concepts and technologies, which influenced major decisions concerning the design and implementation of the framework.

\textit{Future Work} suggests some interesting topics for future research, whose embedding in the framework is meaningful.

\textit{Conclusions} sums up.

\thesissection{Background}

\thesissubsection{The dataflow computational model}
The increased interest in parallelism during the 70's gave rise to the dataflow execution model, which is an alternative to the classical "von-Neumann" model. In the dataflow model, everything is represented in a dataflow graph, where nodes are independent computational units  and edges are communication channels between these units. A node/unit is fired immediately when its required inputs are available and therefore no explicit control commands are needed for execution. Figure \ref{fig:nat} shows a dataflow graph enumerating the set $\mathbb{N}$ of natural numbers.

\mydiag{nat}{Natural numbers}	

In the dataflow graph above, we can discern three types of nodes: sources, which do not have any incoming edge and act as value generators to initiate computation, sinks, which do not have any outgoing edges and inner nodes, which transform one or more incoming streams and redirect their output to other nodes. The \textit{zero} node just produces a stream with a single value 0 and then terminates. \textit{Concat} produces a single stream by concatenating the stream produced by \textit{zero} and \textit{increment}, while \textit{increment} transforms its input stream by adding one to its values. Finally, the sink node displays the result, which is the stream of natural numbers.

Streams can be infinite, such as the stream produced by \textit{concat} because it is the concatenation of a single-value stream and an infinite one. Moreover, the graph is cyclic as \textit{concat} feeds input to \textit{increment} and vice versa. The most interesting fact is that there nodes are independent and therefore can run in parallel. For instance, while \textit{increment} is processing value 5 (i.e. to produce value 6), the previous result (i.e. value 5) passes through \textit{concat} to reach the sink node, which can concurrently process it to display it. 

The main advantage of the dataflow model is its implicit parallelism, deriving from the fact that the computational units are totally independent and therefore can be executed in parallel. A possible single-machine implementation could represent edges as in-memory data storage, whereas a multi-machine one could represent them as channels between TCP sockets, allowing communication across the network. Its great flexibility and composability makes it a good candidate for the underlying architecture of a framework with a high level of abstraction.

\thesissubsection{Functional reactive programming}

A relatively recent programming paradigm is \textit{Functional Reactive Programming (FRP)}, which provides a conceptual framework for implementing reactive (i.e. time-varying and responding to external stimuli) behaviour in \textit{hybrid systems} (i.e. containing both continuous and discrete components), such as robots, in functional programming languages. 

To implement such systems in conventional imperative languages, one must use asynchronous \textit{callbacks} (i.e. each change is handled by a registered \textit{callback} function). Although this solution is satisfactory for simple schemes, more complex scenarios eventually lead to highly incoherent code structure, often called \textit{spaghetti code}, in the sense that control rapidly moves between disconnected parts of the system, similar to the notorious \textit{GOTO} command. This phenomenon stems from the unary nature of \textit{callback} functions, which requires some kind of "internal plumbing" in order to achieve 	mechanisms for handling combination of changes (e.g. when multiple changes occur simultaneously). \textit{FRP} provides a solution to this shortcoming of \textit{callback} functions, because changes are represented as variables (\textit{signals}), which can be passed as parameters to arbitrary functions, called \textit{signal functions}.

\textit{FRP} first appeared as a composable library for graphic animations \cite{fran}, but quickly evolved into a generic paradigm \cite{survey_frp,real_frp,pushpull_frp}. Moreover, extensive research has investigated \textit{FRP} as a framework for robotics \cite{arrows_robots,lambda_in_motion}. 

Although appealing at first, \textit{FRP} was not appropriate for systems  with real-time constraints, due to uncontrollable time- and space- leaks \cite{event_frp}. The solution was a generalization of monads called \textit{arrows} \cite{arrows}, which provided the necessary guarantees that the aforementioned common errors do not occur. Let's see the example of calculating a robot's x-coordinate. Here is the mathematical formula drawn from control theory:

$$ x = 1/2 \int (vr + vl) \cos\theta $$ 

Below is the \textit{FRP} code corresponding to the formula above:

\hs{code/frp1.hs}

As the above may seem counter-intuitive and difficult to understand, a new notation was conceived, notably the \textit{arrow notation} \cite{arrows_notation}:

\hs{code/frp2.hs}

The main advantages of \textit{FRP} are its close correspondence to mathematics\cite{survey_frp}, which make it an ideal framework for modelling real-time systems, and its concise representation of time-varying values via \textit{signals}.

\thesissubsection{Publish-Subscribe model}

\textit{Publish/Subscribe (PubSub)} is a messaging pattern that became popular due to the loose coupling of its components, suited for the most recent large-scale distributed applications.

There is no point-to-point communication and no synchronization. \textit{Publishers} advertise messages of a given type to a specific message class or \textit{topic} that is identified by a \textit{keyword}, whereas \textit{subscribers} listen on a specific \textit{topic} without any knowledge of who the publishers are. The component responsible for relaying the messages between machines and/or processes and finding the cheaper dissemination method is called the \textit{message broker}. Figure \ref{fig:pubsub} illustrates an abstract representation of the \textit{PubSub} model.

\mydiag{pubsub}{PubSub typical layout}

\thesissubsection{ROS: Robot Operating System}

\textit{ROS} is an open-source middleware for robot software, which emphasizes large-scale integrative robotics research \cite{ROS}. It provides a \textit{thin} communication layer between heterogeneous computers, from robots to mainframes and it has been widely adopted by the research community around the world, due to its flexibility and maximal support of reusability through packaging and composability. It provides a compact solution to the development complexity introduced by complex robot applications that consist of several modules and require different device drivers for each individual robot. 

It follows a peer-to-peer network topology, implemented using a topic-based \textit{PubSub} messaging protocol and its architecture reflects many sound design principles. Another great property of \textit{ROS} is that it is language-agnostic, meaning that only a minimal specification language for message transaction has been defined, so contributors are free to implement small-size clients in different programming languages, with \textit{roscpp} and \textit{rospy} being the most widely used ones.

A typical development scenario is to write several \textit{nodes}, that subscribe to some topics and, after doing some computation, publish their results on other topics. The main architectural issue here is that subscribing is realized through asynchronous callback functions, so complicated schemes easily lead to unstructured code, which obviously lead to unreadable and hard-to-maintain code. My approach gives a solution to the aforementioned problem.
 
\thesissubsection{Internet of things - MQTT}

The birth of the Internet gave rise to a concept called \textit{Internet of Things (IoT)}, which is essentially the ability of many heterogeneous devices, ranging from low-cost sensors to vehicles with embedded electronics, to collect data and exchange it amongst themselves using the Internet. This gave rise to smart grids, smart homes and eventually smart cities. 

The development of such systems though, due to their heterogeneity, is rather complex and costly. Typical software architectures were not meant to be used in such environments and therefore new tools and concepts needed to be invented. Recent development of a variety of middleware frameworks, showed that a standard protocol of communication is imperative along with supporting tools\cite{iot_middleware}. The most widely spread protocol is \textit{MQTT}, which follows the \textit{PubSub} messaging pattern and provides a very minimal communication layer in order not to put a strain on the resource-bounded system\cite{mqtt}. 

For instance, an \textit{IoT} application could connect to some sensors by subscribing to their corresponding topics, taking decisions that would result in some commands to some actuators, by publishing to their corresponding topics.

Fortunately, the dataflow model seems to be rather fitting for these scenarios\cite{iot_dataflow}, as every node in the graph is completely independent, and consequently can be any "\textit{thing}". This useful property of the model makes it a good architectural choice for such applications. The only thing to consider is how these things will communicate in a standard way, so as to be able to add new types of \textit{things} and integrate it in an effortless way to an existing dataflow network.

\thesissubsection{The Reactive Streams Standard}

\textit{PubSub} is widely used by different frameworks but still lacks standardization. The \textit{Reactive Streams Standard (RSS)} is an initiative to provide a standard for asynchronous stream processing with non-blocking back pressure. This encompasses efforts aimed at runtime environments (JVM and JavaScript) as well as network protocols \cite{rss}.

\textit{RSS} defines two minimal interfaces for the roles of \textit{Subscriber}\site{http://www.reactive-streams.org/reactive-streams-1.0.0-javadoc/org/reactivestreams/Subscriber.html} and \textit{Publisher}\site{http://www.reactive-streams.org/reactive-streams-1.0.0-javadoc/org/reactivestreams/Publisher.html}. A \textit{Subscriber} implementation should define reactions to observed values, including normal and erroneous termination, whereas a \textit{Publisher} implementation should accept requests from \textit{Subscribers} and start emitting values to them.

Below we see a minimal example of using \textit{RSS} to define a publisher that emits values 1..10 and a subscriber that prints all observed values and finally connect them together.

\jvs{code/rss.java}

\thesissection{Requirements}

The design was heavily influenced by principles set out by the FRP and dataflow models. 

\thesissubsection{Reactive}

The system is \textit{reactive}, as close as possible to the definition of the Reactive Manifesto \cite{manifesto}. 

The system is \textit{responsive}, meaning it should be able to handle time-sensitive scenarios if at all possible. This is the cornerstone of usability and utility, but more than that, it enables quick error-detection and error-handling.

The system is \textit{resilient}, meaning it is able to recover robustly and gracefully after a failure, due to the fact that nodes in the dataflow graph are completely independent and recovery of each one can be done in isolation. Another thing to note here is that special error messages are built-in and make it very easy to propagate errors between \textit{components}, in case the error-handling part of a component is decoupled from the computational logic. This leads to much more robust architectures for large-scale systems, where fault-tolerance is mission-critical.

The system is \textit{elastic}, meaning it will adjust itself depending on the available resources and demanded workload. For instance, the granularity of the graph (i.e. number of nodes) is adjusted so as to match a heuristic-based value (e.g. total number of threads).

The system is \textit{message-driven}, meaning it relies solely on asynchronous message-passing for inter-component communication leading to loose coupling, isolation, location transparency and the error propagation mentioned above. Location transparency is critical to preserve the semantics whether on a single host or a machine cluster. 

\mydiag{manifesto}{Reactive properties}

\thesissubsection{Heterogeneous}

One of the major concerns while designing the framework was the ability to deploy it anywhere, from low-cost robots to mainframes. Obviously, such attribute would require a very flexible runtime environment. To satisfy this requirement, the strategy design pattern was used for evaluation, meaning that the core system only builds the internal representation of the dataflow graph and partitions it across the available computational resources. From there onwards, each partial graph can be evaluated by a different \textit{EvaluationStrategy} (see Implementation chapter), which could interpret it using the Java 8 Streams library\cite{java_streams} or even compile into CUDA code for execution on a GPU.

Figure \ref{fig:heterogen} illustrates a simple example of a robot application pipeline, where input to the dataflow graph is what the robot's camera senses and, after some image processing and some computation-heavy decision making, a command to an actuator of the robot is executed. Orange nodes are deployed on the robot's on-board computer, the green node is deployed on an off-board GPU and the red node is deployed on the main server.

\mydiag{heterogen}{Heterogeneity pipeline}

\thesissubsection{Extensible}

As the work described in this thesis is quite fundamental and ambitious, it seemed highly unlikely that it would reach closure within the context of an undergraduate thesis. Therefore, careful consideration was taken to compose the system of different independent modules, which could easily be extended or modified, in order to allow many future contributions.

With that concept in mind, generality and abstraction were heavily emphasized during both the design and the implementation process. We can say now we are satisfied with the level of abstraction the core system has reached and hope the stressful refactoring that the framework went through will blossom in the form of future contributions.

\thesissubsection{Abstract}

The framework is \textit{abstract} in terms of implementation details, as it is completely agnostic of any machine-specific requirements. It is designed as a unifying conceptual base for further extensions and careful consideration was taken not to restrict in any aspect, architectural or not. This was achieved by making many parts of the core system pluggable, allowing for easy refactoring on most of its internal functionality. Moreover, the internal graph representation does not include information on how a node is executed, but only on its semantics.

\thesissection{Approach}

\thesissection{Implementation}
This section examines the major characteristics of the framework's implementation.

\thesissubsection{The Strategy design pattern}

In software engineering, and especially in \textit{object-oriented programming (OOP)}, a \textit{design pattern} is a general repeatable solution to a commonly occurring problem in software design \cite{design}.

One such solution, the \textit{Strategy} design pattern is used when a particular algorithm can be implemented by a variety of behaviours/classes \cite{design}. In such a case, a good idea is to isolate the algorithm in a separate \textit{interface} and allow the system to select the appropriate instantiating classes at runtime.

Figure \ref{fig:strategy} illustrates the basic UML diagram of the strategy design pattern.

\begin{figure}[h!] 
	\centering
	\includegraphics[scale=0.1]{strategy}
  	\caption{Strategy design pattern}
  	\label{fig:strategy}
\end{figure}

\thesissubsection{Notifications}
Every value passed through the framework's \textit{streams} is wrapped inside a \textit{Notification} object, which discriminated stream values into three categories: \textit{onNext} (when the stream provides a regular value), \textit{onError} (when an error occurs) and \textit{onComplete} (when the stream completes its output).

\thesissubsection{External Input-Output}
In order to make the framework easy to integrate with other stream and/or dataflow technologies, I decided that every input/output node (i.e. publisher/subscriber in the \textit{PubSub} terminology or source/sink in the dataflow terminology) should implement the interfaces that \textit{RSS} defines.

A sink node (output) should implement the Subscriber interface \site{http://www.reactive-streams.org/reactive-streams-1.0.0-javadoc/org/reactivestreams/Subscriber.html}, which essentially defines three methods corresponding to reactions to a \textit{Notification}, one for each of the categories mentioned above. 

A source node (input) should implement the Publisher interface\site{http://www.reactive-streams.org/reactive-streams-1.0.0-javadoc/org/reactivestreams/Publisher.html}, which defines a single method \textit{subscribe(Subscriber)}, where a Subscriber requests the Publisher to start emitting values. 

Many existing technologies provide these interfaces, or at least adapters from their internal representations, and therefore they are very easy to be integrated to the framework.

\thesissubsection{Software structure}
The core system\site{https://github.com/rhea-flow/rhea-core} is organized in the following top-level packages:

\begin{tabularx}{\textwidth}{rX}
	\textit{org.rhea\_core.internal} 
	& all internal functionalities such as graphs, expressions and notifications \\
	\textit{org.rhea\_core.evaluation}
	& everything associated with the evaluation of the constructed dataflow graph \\
	\textit{org.rhea\_core.distribution}
	& everything associated with distributing the evaluation across the available computational resources \\
	\textit{org.rhea\_core.optimization}	
	& includes some built-in optimizers for adjusting the  granularity of the graph \\
	\textit{org.rhea\_core.network}	
	& everything associated with networking \\
	\textit{org.rhea\_core.io}
	& defines the interfaces that sources/sinks should implement \\
	\textit{org.rhea\_core.util}
	& helpful utilities needed throughout the project \\
\end{tabularx}

\thesissubsection{Internal representation}

For representing the internal structure of the dataflow graph, the \textit{JGrapht} open-source Java library was used, which provides many graph data structures and common graph-theory algorithms\cite{jgraph}. The main class representing the internal dataflow graph is \textit{FlowGraph},  which is located in the \textit{org.rhea\_core.internal} package.

\thesissubsection{Stream variables}

The construction of the aforementioned internal graph is always implicit, through a rich set of stream operators. The only data type handled by the programmer is \textit{org.rhea\_core.Stream}, which contains the parametric type of its single output. Each \textit{Stream} object contains internally a \textit{FlowGraph}, which is only to be accessed and manipulated by the internal module, evaluation strategies and optimizers.

Figure \ref{fig:simple} illustrates the dataflow graph(left) produced by the framework code(right) using the \textit{Stream} data type.

\codefig{simple}{\jv{code/simple.java}}{Simple stream example}

These variables can be used, preferably together with their parametric type, and reused in different parts of the graph. This is necessary, for instance, when you wish to split a node's output to different inputs. Figure \ref{fig:split} shows such an example.

\codefig{split}{\jv{code/split.java}}{Split example}

\thesissubsection{Stream operators}

\thesissubsection{Evaluation}

Every primitive operator corresponds to an expression implementing the \textit{Transformer} interface, defined in the \textit{org.rhea\_core.internal.expressions} package. 

A complete dataflow is defined by a \textit{Stream} variable and an object implementing the \textit{Output} interface, which can be either an \textit{Action}, a \textit{Sink} or a list of these. 

In order to evaluate a constructed dataflow graph the strategy design pattern is used, therefore a class implementing the \textit{EvaluationStrategy} interface, found in the \textit{org.rhea\_core.evaluation} package, needs to be provided. An \textit{EvaluationStrategy} just takes the \textit{Stream} variable and its corresponding \textit{Output} and executes it, however desired.

The strategies I have implemented so far follow:

\begin{description}[style=nextline]
\item[RxJavaEvaluationStrategy\site{https://github.com/rhea-flow/rx-eval}] 
Uses rxjava\site{https://github.com/ReactiveX/RxJava}, which is a famous and well-maintained library for asynchronous programming using the \textit{Observable} type, which is very close, semantically, to my \textit{Stream} type.

\item[RosEvaluationStrategy\site{https://github.com/rhea-flow/ros-eval}] 
Integrates the \textit{ROS} middleware into the framework, by providing the \textit{RosTopic} class, which implements the \textit{AbstractTopic} interface defined in the \textit{org.rhea\_core.io} package. This strategy's job is to set up a \textit{ROS} client and configure every \textit{RosTopic} used within the dataflow that needs to be evaluated to use this client. After that, evaluation is propagated to a generic strategy (e.g. rxjava).

\item[MqttEvaluationStrategy\site{https://github.com/rhea-flow/mqtt-eval}] 
Integrates the MQTT middleware into the framework, in the same way \textit{ROS} is intergrated.
\end{description}

\thesissubsection{Distribution}

An evaluation strategy executes the requested dataflow graph in a single machine, without concern about distribution and resource utilization.

For distribution and cluster management, the strategy design pattern is used again, specifically the \textit{DistributionStrategy} interface, which is defined in the \textit{org.rhea\_core.internal.distribution} package. Its responsibility is to take the whole initial graph that we need to evaluate and, after adjusting its granularity (i.e. size) to fit the available resources (see \textit{Optimization} section), partition it across all computational resources, maybe using different evaluation strategies.

\thesissubsubsection{Hazelcast}

Due to the RSS being in its infant stage, no working implementation exists for superimposing a network protocol onto it (e.g. RSS over TCP). For this reason, I relied upon the open-source \textit{Hazelcast} library\cite{hazelcast} to discover and manage multiple machines and used its internal decentralized \textit{PubSub} model to communicate intermediate results across the network. Figure \ref{fig:partition1} illustrates a dataflow graph on the left and the same graph partitioned over several machines on the right.

\twofig{partition1}{partition2}{Partitioning}

\thesissubsubsection{Machine configuration}

According to the distribution strategy being used, the available machines will require a certain initial configuration. For the \textit{Hazelcast} case, a little piece of setup code needs to be executed on every member of the cluster, which is together with the main \textit{Strategy} class. Moreover, helpful information can also be added at this step, such as number of CPU cores. It is the distribution strategy's responsibility to ensure that this information is properly distributed and handled.

Apart from this initial configuration, the distribution strategy needs to enable members to declare certain skills that they possess, which are required by specialized nodes. For instance, a source node emitting values from a \textit{ROS} topic must be executed on a machine having \textit{ROS} installed, in order to set up a \textit{ROS} client. In the \textit{Hazelcast} case, these skills are just \textit{strings} and are declared in the initialization code of each machine separately.

\thesissubsection{Serialization}

As communication between machines across a network is mandatory, data types emitted through the streams must be serialized on departure and de-serialized on arrival at each machine. For this reason, each \textit{DistributionStrategy} must be configured with a class implementing the \textit{Serializer} interface, define in the \textit{org.rhea\_core.serialization} package. The byte representation of the objects is parametric for maximum flexibility. 

A default \textit{Serializer} is provided with the core system, which can serialize every class implementing the \textit{Serializable} interface. In addition to that, the JsonIO library\cite{json_io} is used which allows serialization of many types of classes, but still does not cover every possible one. Figure \ref{fig:serialization} depicts the serialization process in more detail.

\mydiag{serialization}{Serialization process}

\thesissection{Optimization}

This chapter describes three stages of optimization the dataflow graph goes through before being evaluated. To aid extensibility  the strategy design pattern is again used, whose corresponding interface \textit{OptimizationStrategy} resides in the \textit{org.rhea\_core.optimization} package. Figure \ref{fig:optimization} illustrates the optimization stages.

\mydiag{optimization}{Optimization stages}

\textit{Proactive filtering} transforms the graph, by moving filters as earlier in the pipeline as possible, to achieve less data movement between nodes, which results in better performance.

\textit{Granularity adjustment} fuses nodes together to dynamically resize the graph to a granularity that fits the available resources. This step follows \textit{proactive filtering}, as the latter enables many opportunities for node fusion.

\textit{Node placement} decides on which of the available machines each node will be executed, to achieve better utilization of the available resources. This is the last step, because after deploying the nodes to the chosen machines, the structure of the dataflow graph remains static.

Thus, the optimized graph that is the output of the above process is most likely to achieve better performance and utilization of the available resources than the initial one.

\thesissubsection{Proactive filtering}

The first optimization stage is a heuristic one, based on the fact that if a filter operation can be moved earlier (i.e. closer to source nodes) while preserving the original semantics, then there will be benefit concerning computational cost and cross-machine communication overhead. The figures below show the corresponding graph transformations.

\thesissubsubsection{Transformations}

The figures below illustrate one representative example of each general class of graph transformation

\optimization{maptake}{Take/skip/distinct before map}
\optimization{mapfilter}{Filter before map}
\optimization{concatdistinct}{Filter/distinct before concat/merge}

\newpage
\thesissubsubsection{Example}

Figure \ref{fig:proactive} illustrates the \textit{proactive filtering} optimization stage, using the transformation shown in figures \ref{fig:combmapfilter}, \ref{fig:concatdistinct} and \ref{fig:maptake}, in this order. The resulting dataflow graph have much less data movement, leading to less computation overall, but most importantly, less communication overhead, in the case it is deployed on several remote machines.

\optimization{proactive}{Proactive filtering example}

\thesissubsection{Granularity adjustment}

Different nodes of the dataflow graph will be executed on a separate thread/process. The fact that graphs can grow very big, for instance when programming a big swarm of millibots\cite{army}, poses a problem when available computational resources are limited. For this reason, the second optimization stage tries to adjust the granularity of the dataflow graph to a desired value, which is the number of available threads amongst all machines. 

\thesissubsubsection{Transformations}

To reach the desired granularity, the optimizer applies some semantic-preserving transformation, as shown in the figures below (for simplicity, only a single example of each general case is demonstrated). 

\optimization{mergemap}{Merge maps}
\optimization{embedmap}{Embed map in creation}
\optimization{embedrepeat}{Embed repeat in creation}
\optimization{combmapfilter}{Combine map with filter}
\optimization{combfilterexists}{Combine filter with exists}
\optimization{combmapexists}{Combine map with exists}
\optimization{combmapzip}{Combine map with zip}
\optimization{combzipmap}{Combine zip with map}
\optimization{meaningless}{Meaningless nevers}

\newpage
In figure \ref{fig:mergemap} we merge two \textit{map} operations into one \textit{map} operation that uses the composition of the two initial functions, while in figures \ref{fig:embedmap} and \ref{fig:embedrepeat} we utilize Java's built-in stream operators on its collections, namely \textit{map} and \textit{repeat}. In figure \ref{fig:combmapfilter} a \textit{map} followed by a \textit{filter} is substituted by a more complex equivalent operation, namely \textit{filterMap}, while in figures \ref{fig:combfilterexists} and \ref{fig:combmapexists} we apply some simple properties of the boolean functions involved to decrease the number of nodes. In figures \ref{fig:combmapzip} and \ref{fig:combzipmap} we utilize function composition to embed \textit{map} operations into \textit{zip} operations. Lastly, in figure \ref{fig:meaningless} we remove sub-graphs that are not reachable, due to \textit{never} operations.

\thesissubsubsection{Example}

Figure \ref{fig:granularity} illustrates how a dataflow graph of granularity equal to 9 is optimized for execution on a quad-core computer, by applying transformation shown in figures \ref{fig:embedrepeat}, \ref{fig:mergemap}, \ref{fig:combmapzip} and \ref{fig:combzipmap}, in this order. The resulting graph has much lower overhead, caused by thread switching, due to the fact that it takes into account the number of threads available at runtime.

\optimization{granularity}{Granularity adjiustment example}

\thesissubsection{Node placement}

After the first two passes, we have an optimized dataflow graph with fine-tuned granularity. At this stage, nodes are mapped to tasks and are deployed across the available machines. 

If the desired granularity has not been reached yet, the \textit{DistributionStrategy} applies fusion to pairs of tasks until it reaches it, as shown in figure \ref{fig:fusion}.

\optimization{fusion}{Task fusion}

The final decision to be made is where each of these newly constructed tasks will be executed, although some of them need to necessarily be placed on specific machines with certain skills. 

Apart from these hard constraints, we need to minimize communication overhead. For this purpose, the strategy design pattern is again used, namely the \textit{NetworkProfileStrategy} that is defined in the \textit{org.rhea\_core.distribution} package. Its responsibility is to calculate a network distance between each pair of available machines, which is fed as input to the \textit{NodePlacement} optimizer. 

At this stage, we identify the aforementioned network distance as cost and apply brute-force to find the optimal placement of the (groups of) tasks that minimize that cost.

\thesissection{Applications}
This chapter will demonstrate some use-cases of the framework, which can be found in the framework repository\cite{rhea}. At first, a mathematical example is shown, which is followed by three robotic applications. 

\thesissubsection{Hamming numbers}
Consider the problem of enumerating the \textit{Hamming numbers}, which are generated by the mathematical formula $\mathbb{H} = 2^i3^j5^k$, where $i,j,k \in \mathbb{N}$. There is an intuitive dataflow solution to the above problem, taken from the book of \textit{Lucid}, which is the first functional dataflow language\cite{lucid}. Figure \ref{fig:hamming} shows the dataflow graph on the left and the corresponding \textit{RHEA} code on the right.

\codefig{hamming}{\scalas{code/hamming.scala}}{Hamming numbers}

The code is written in Scala to utilize the \textit{Pimp my library} design pattern\cite{pimp}, which is used to easily add new functions to already existing libraries, using Scala's \textit{implicit conversions} (line 28). In the example above, we define two new Stream operators, namely \textit{multiply} (line 10), which just multiplies the stream with a constant, and \textit{mergeSort} (line 13), which produces an ordered stream given two ordered streams as input. We also see the power of the \textit{loop} operator (line 2), which allows us to define cycles in an effortless manner.

\thesissubsection{Camera surveilance}

Moving to a more realistic, but still minimal, use-case, this example demonstrates how cleanly we can express a surveillance application from a robot's camera.

The camera should send frames to be displayed on the screen, only when motion is detected. Figure \ref{fig:surveillance} shows the dataflow graph on the left and the corresponding \textit{RHEA} code on the right.

\codefig{surveillance}{\jvs{code/surveillance.java}}{Camera surveillance}

In the code above, we can see how easy it is to view a \textit{ROS} topic as a stream, using the \textit{RosEvaluationStrategy} (line 3). Moreover, there is a nice separation between program logic (stream declaration in lines 6-17) and implementation details (\textit{motionDetected} function in line 19).

\thesissubsection{Robot control panel}

This application concerns real-time monitoring of a robot, that is publishing its information and sensor-data to \textit{ROS} topics, through a \textit{graphical user interface (GUI)}.

The \textit{/camera/rgb} topic provides the frames of the robot's camera as coloured images, while the \textit{/camera/depth} provides frames that provide depth information. The \textit{/tf} topic publishes parent-child relations of the internal topics of the robot's configuration, and finally the \textit{/scan/} topic provides information from the robot's laser that gives horizontal depth information in polar coordinates.

The GUI displays the laser data embedded on the camera stream, while allowing for real-time face detection. Additionally, it displays the depth frames and the \textit{tf} relations as a tree. Finally, a mock-up battery bar is displayed to show-case the framework's ability for simulation. Figure \ref{fig:control_panel} illustrates the dataflow solution to the above problem on the left and the corresponding \textit{RHEA} code on the right.

\codefig{control_panel}{\jvs{code/control_panel.java}}{Robot control panel}

The implementation details (i.e. the visualization class and methods \textit{faceDetect}(line 7), \textit{embedLaser}(line 8) and \textit{toGray}(line 26)) are not shown for brevity's sake. It is evident that this model of programming encourages a clean separation of concerns between the individual components, namely between the sensor data manipulation and the actual visualization on the GUI. 

\thesissubsection{Robot hospital guide}

As a final example, we will examine a more IoT-based application. Consider a robot that guides patients to different parts of a hospital, such as the gym or cafeteria. Assuming map localization , path finding and obstacle avoidance are already implemented, there still remains a problem with calibrating the robot's speed according to the patient's status. 

To keep tract of the patient's distance from the robot, each patient carries a smart-phone that acts as a \textit{bluetooth low-energy (BLE) beacon}. The robot uses its bluetooth receiver to publish the distance from the signal source to an \textit{MQTT} topic, which is then transformed by our stream application to velocity commands for the robot, in the form of slowing down or speeding up.

The first module constitutes the main program logic, where a declared dataflow graph acts as a stream transformation from beacon information to velocity commands to the robot. Figure \ref{fig:hospital} shows the dataflow graph on the left and the corresponding \textit{RHEA} code on the right.

\codefig{hospital}{\jvs{code/hospital.java}}{Robot hospital guide}

The second module just uses the \textit{ReactiveBeacons} library\site{https://github.com/pwittchen/ReactiveBeacons} to get a stream of beacon data via \textit{rxjava}, and then publishes it to a \textit{MQTT} topic, which is the input of the first module. The corresponding \textit{RHEA} code follows:
\\
\jvs{code/rxbeacon.java}

This example clearly show-cases the framework's ability to combine different technologies and act as a high-level, declarative coordination language.



\thesissection{Related Work}

This section discusses related work in the fields of \textit{Big Data}, \textit{Robotics} and \textit{IoT}.

\thesissubsection{Big Data}

The necessity for implicit parallelism and distribution of more and more applications, dealing with huge and/or complex data, has brought increasingly more attention to the dataflow programming model. The main reason many frameworks have adopted it, is the high level of abstraction it provides with its declarative approach, making it simple to structure and maintain a complex system, while at the same time not losing its expressive power.

\thesissubsubsection{MapReduce}

\textit{MapReduce} was developed by Google and provides a very simple model, and corresponding runtime, that allows automatic concurrency/distribution on a cluster by allowing only a very minimal program structure. First, the user specifies a \textit{map} function that processes a key/value pair to generate a set of intermediate key/value pairs, and a \textit{reduce} function that merges all intermediate values associated with the same intermediate key. Although it was widely adopted at first, quickly many problems that could not be expressed with the above formalism were found and therefore a more expressive model was required.

\thesissubsubsection{Flumejava}

A generalization of the \textit{MapReduce} framework is \textit{FlumeJava}, again developed by Google, which tries to overcome its \textit{MapReduce's } shortcomings, by allowing more expressive pipelines consisting of multiple \textit{MapReduce} stages. Additionally, \textit{FlumeJava} provides some more abstract operations that, when evaluated, are compiled into primitive \textit{MapReduce} steps.

Although \textit{FlumeJava} was more attractive due to its expressibility, still the pipeline constructed could not formulate all problems that are needed in many big-data applications. For instance, the constructed dataflow could not contain cycles, which is an integral part of \textit{incremental computation}, used extensively nowadays for machine learning and data analysis.

\thesissubsubsection{Spark}

A very well-known and well-adapted framework for scalable large-data processing is Apache's \textit{Spark}\cite{spark}. Although not a dataflow framework, it was developed to overcome the shortcomings of the \textit{MapReduce}, similar to \textit{FlumeJava}, by providing a much more efficient and flexible runtime.

It follows the same general approach as \textit{RHEA}, in the sense that it is completely generic and encourages domain-specific libraries to be built upon it. For instance, \textit{MLib}\site{http://spark.apache.org/mllib/} is a library for machine learning and \textit{GraphX}\site{http://spark.apache.org/graphx/} is a library for iterative graph algorithms, both stacked upon \textit{Spark}.

It offers a rich set of data-parallel operators ($\simeq 80$) that can be used interactively from Scala, Python, Java or R. The code below shows the classic word-counting example in Spark's Scala API.

\scala{code/spark.scala}

\thesissubsubsection{Cloud Dataflow}

Continuing the search for more expressive models, Google recently released the \textit{Cloud Dataflow} framework\cite{google_dataflow}, which is an evolution of \textit{FlumeJava}\cite{flumejava}, allowing cycles and therefore incremental computation.

It is a completely domain-agnostic dataflow framework integrated with many other closely-related technologies from Google\site{https://cloud.google.com}, like Cloud Storage, Cloud PubSub, Cloud Datastore, Cloud Bigtable and BigQuery. 

It is open-source, offers fully automatic resource management that auto-scales for optimal throughput and provides increased reliability and data consistency. Moreover, it provides a unified programming model through its API, while allowing data monitoring and demand-driven execution.

In contrast to \textit{RHEA}, graphs constructed by \textit{Cloud Dataflow} are designed to be deployed only on cloud infrastructures, and therefore no support for complete heterogeneity is provided. In terms of network optimization, namely node placement,  \textit{Cloud Dataflow} lets the cloud system targeted to make all decisions, while \textit{RHEA} profiles the network and decides autonomously. 

\thesissubsubsection{Stratosphere}

In contrast to the, more or less, imperative approach of all preceding frameworks, which enables automatic distribution/concurrency by using immutable data structures. On the other hand, \textit{Stratosphere}\cite{stratosphere}, like \textit{RHEA}, follows a declarative programming approach which enables writing highly parallel code directly from the language's semantics. 

Apart from offering a language of a much higher abstraction level, \textit{Stratosphere} has internalised several interesting and novel approaches to optimization of dataflow graphs, especially concerning cyclic graphs (i.e. incremental computation)\cite{spinning}. These optimizations are generic, in the sense that most frameworks can adopt them without much effort. Integrating these optimization into \textit{RHEA}, as future work, would certainly be of great benefit to the performance of the system.

\thesissubsubsection{Naiad}

Another high-level dataflow system that follows a declarative approach similar to \textit{RHEA} is \textit{Naiad}, which unifies incrementally iterative computations with continuous data ingestion into a new
technique called differential computation.

Offering the high throughput of batch processors, the low latency of stream processors and the ability to perform iterative and incremental computations at the same time is extremely challenging and none of the aforementioned frameworks manage to provide it. Applications that need all these features need to rely on multiple platforms, at the expense of efficiency, maintainability and simplicity.

\textit{Naiad}\cite{naiad} combines all of these features in a unifying framework, that provides a generic low-level platform, that a wide variety of high-level programming models can be built upon, enabling such diverse tasks as streaming data analysis, iterative machine learning, and interactive graph mining.

Its main contribution is the definition of a new computational model, namely the \textit{Timely Dataflow} model, which is an extension to the dataflow model I introduced in the first chapter, by allowing a more efficient and lightweight coordination mechanism for capturing opportunities for parallelism. This is achieved by enriching the dataflow model with timestamps that represent logical points in the computation.

Figure \ref{fig:naiad} shows a \textit{Naiad} application that supports real-time queries on continually updated data.

\myimage{naiad}{0.7}{Naiad application}

\thesissubsubsection{Akka}

Definitely one the most mature frameworks for distribution targeting the JVM, \textit{Akka}\cite{akka} is a toolkit and runtime for highly concurrent, distributed and resilient message-driven applications. It is also one of the founders of the \textit{Reactive Streams}\cite{rss} initiative.

Its approach follows the \textit{Actor} model\cite{actor}, where one perceives abstract computational agents, called actors, that are distributed in space and communicate with point-to-point messages that are buffered in a queue. In reaction to a message, an actor can create more actors, make local decisions, send more messages and determine how to respond to the next message received.

Similar to the problem of \textit{ROS} that my framework solved, which is the inappropriate nature of callbacks for complex scenarios, \textit{Akka} developers also felt the necessity for a more flexible and composable programming model, so they developed the \textit{AkkaStreams} library\site{http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0-M2/scala.html} which provides a convenient API for stream processing and also dataflow graph construction with an interesting DSL. Figure \ref{fig:akka} demonstrates a dataflow graph on the left, generated by the DSL code on the right.

\usemintedstyle{friendly}
\codefig{akka}{\scala{code/akka.scala}}{Akka DSL}		

The main reason \textit{RHEA} offers a more flexible solution to \textit{ROS} shortcomings than \textit{Akka}, is that \textit{Akka} is a pretty heavyweight library, and consequently may prove over-abundant for simple use-cases. On the other hand, \textit{RHEA} offers the ability to choose between several \textit{EvaluationStrategies} to match your application's needs, therefore a simple application would just use a lightweight library like \textit{rxjava}.

\thesissubsubsection{dispel4py}

A less-known framework for Python is \textit{dispel4py}\cite{dispel}. It provides the ability to describe abstract workflows for distributed data-intensive applications.

Similar to my \textit{EvaluationStrategy} concept, it allows different mappings to enactment systems, such as MPI\cite{mpi} and Apache Storm\cite{storm}.

Its main disadvantages are that it has only an API for Python and only allows low-level specification of the graph's nodes, through the definition of \textit{Processing Elements}. Therefore, it is inconvenient to compose larger graphs from simpler ones and the source code becomes chaotic and difficult to maintain.

\thesissubsection{Robotics}

It is only natural that the dataflow model would make its way through the field of robotics, as many behaviours in control theory are expressed as dataflow diagrams. 

\thesissubsubsection{roshask}

\textit{Roshask}\cite{roshask} is a binding from the Haskell programming language to the basic \textit{ROS} interfaces. Like \textit{RHEA}, the approach is to overcome the shortcomings of \textit{ROS} callbacks by viewing topics as streams. This allows for, and encourages, a higher level of abstraction in robot programming, while making the fusing, transforming and filtering of streams fully generic and compositional. 

Below is the classic Talker-Listener \textit{ROS} example, where one node publishes messages to a topic and another one listens for them.

\hs{code/roshask.hs}

\thesissubsubsection{Yampa}

\textit{RHEA} and \textit{roshask} were heavily influenced by the work of Hudak's group (Yale Haskell Group) on robot DSLs and FRP in general\cite{fran, arrows_robots,lambda_in_motion,event_frp,real_frp,pushpull_frp}.

\textit{Yampa}\cite{yampa} is a DSL embedded in Haskell that realizes the FRP model, using arrows to minimize time-/space- leaks. Figure \ref{fig:yampa} shows the primitive stream operators that are supported. 

\myimage{yampa}{1}{Yampa operators}

\thesissubsubsection{Flowstone}

\textit{Flowstone}\cite{flowstone}  is a programming environment that mixes graphical and text based programming in Ruby that can be used for robotics, image/signal processing and interconnecting heterogeneous sources. It follows a variant of the dataflow model, where applications are built by linking together functional blocks called components. Figure \ref{fig:flowsotne} shows a screenshot of the graphical environment, where we discern both graphical and textual elements.

\myimage{flowstone}{0.45}{Flowstone screenshot}

Its main advantage is that it is stand-alone, so no compiling is necessary, which allows for rapid prototyping.

\thesissubsection{Internet of Things}

IoT applications often deal with much heterogeneity, due to the variety of sources that different devices introduce. Therefore, a component-based approach suits well to solve this problem and there are some dataflow frameworks that follow that approach.

\thesissubsubsection{NoFlo}

\textit{NoFlo}\cite{noflo} is a JavaScript implementation of \textit{Flow-based Programming}\cite{fbp}, which is a particular form of dataflow programming, based on bounded buffers, information packets with defined lifetimes, named ports and separate definition of connections.

\textit{NoFlo} applications consist of components that are connected together in a graph. This allows for clear separation of control flow from the actual software logic, helping you organize large applications easier than traditional OOP paradigms. 

You can design \textit{NoFlo} applications using a web-based graph editor\site{https://flowhub.io/}, which is depicted in figure \ref{fig:noflo}.

\myimage{noflo}{0.7}{NoFlo graph editor}

\thesissubsubsection{Node-RED}

Another interesting \textit{IoT} tool for JavaScript following a dataflow approach is \textit{Node-RED}\cite{node-red}, which is a visual tool for wiring together hardware devices, APIs and online services in new and interesting ways. 

Applications called flows, are built immediately on a browser, and can be deployed on the Cloud with just a single click. The main advantage of this tool is that it encourages social development, due to the fact that flows are stored in JSON format, which can be easily imported and exported for sharing with others. The online flow library\site{http://flows.nodered.org/} has had a huge number of contributions so far. Figure \ref{fig:nodered} shows a screenshot of the editor.

\myimage{nodered}{0.37}{Node-RED graph editor}

\thesissubsection{Miscellaneous}

\thesissubsubsection{TensorFlow}

Another dataflow framework from Google is \textit{TensorFlow}\cite{tensor_flow}, which is an open-source polyglot library for machine learning and especially construction of neural networks.

The interesting fact is that, although it started out as a rigid neural network library, it quickly generalized to a dataflow construction library, much similar to my own project, which started out as a robotics library. 

Its main features are its portability to multiple computational architetures (e.g. CPU, GPU, etc...) and multiple language APIs (e.g. C++, Python), although its main advantage are its domain-specific operators for neural nets (i.e. common subgraphs, auto-differentiation).

Through the edges/streams connecting the nodes, only a single but flexible data type is allowed, namely the \textit{Tensor} type, which essentially is a multi-dimensional array that usually represents features or weights. In contrast to \textit{RHEA}'s Streams, \textit{Tensors} cannot be infinite, mainly due to the fact that their size is determined by the dimensionality of the problem being solved, which is, in most cases, a fixed constant.

Figure \ref{fig:tensorflow} illustrates a neural network as a dataflow graph.

\myimage{tensorflow}{0.5}{TensorFlow graph}

\thesissubsubsection{Ziria}

The dataflow computational model also found applications in the field of wireless systems programming, particularly in the domain of \textit{software-defined radio (SDR)}. 

\textit{Ziria}\cite{ziria} is a DSL that offers programming abstractions suitable for wireless physical (PHY) layer tasks while emphasizing the pipeline reconfiguration aspects of PHY programming. \textit{Ziria} also implements many specialized optimization steps that enable it to be on par and in many cases outperforms a hand-tuned state-of-the-art C++ implementations on commodity CPUs.

\thesissection{Future Work}

This section discusses interesting topics and ideas for future contribution and extension of the framework.

\thesissubsection{More strategies}

Every component that was initially intended to be replaceable for the sake of flexibility, was implemented using the strategy design pattern. So the definite starting point for contribution would be to implement more concrete strategies.

For evaluation, a good idea would be a low-level implementation in C/C++ to allow compatibility with older/smaller systems, not capable of running the JVM. Additionally, more JVM-based strategies are possible, by using the standard \textit{java.util.Stream} library\cite{java_streams}, \textit{Akka Streams} or Scala \textit{Iteratees}\cite{iteratees}.

For distribution, again a more low-level approach written in C/C++ (e.g. using \textit{MPI/OpenMP}) would be beneficial to the variety of systems that are allowed to cooperate freely. Moreover, many frameworks similar to Hazelcast could replace it to allow for easy integration with applications that are already committed to another framework.

\thesissubsection{Dynamic reconfiguration}

A definite shortcoming of \textit{RHEA} is that all configuration takes place initially and remains static throughout execution. This poses a problem for many scenarios, where environment is constantly changing and available resources may be introduced or become obsolete. 

For instance, in a distributed application that controls the behaviour of a \textit{robot swarm} and all communication is done through a \textit{wireless local area network (WLAN)}, a robot may lose signal and become unavailable at runtime. Later on it may rejoin the network, so it is vital that its sensor input and computational power become quickly available to the system. A nice DSL that is used to specify adaptive behaviour in robot navigation can be found on \cite{reconf_robot}.

Apart from robotics, the need for adaptive behaviour of software systems has been evident for a long time\cite{reconf_survey}. There have also been attempts for runtime adaptation of, specifically, stream processing systems, such as the \textit{Flextream} framework\cite{flextream}. 

A JVM-based technology that is relatively easy to integrate into \textit{RHEA} is \textit{HotWave}\cite{reconf_java}, which is an \textit{aspect-oriented programming (AOP)} framework, based on the famous \textit{AspectJ}\cite{aspect} open-source extension of Java, that supports dynamic (re)weaving of previously loaded classes, and ensures that all classes loaded in a JVM can be (re)woven. The contribution idea here is to integrate \textit{HotWave} into the \textit{org.rhea\_core} package and then use it to specify the desired adaptive behaviour for reconfiguring where nodes are executed, what operation they perform, and so forth.

\thesissubsection{Advanced network profiling}

The current strategy for network profiling is based on \textit{round-trip time (RTT)} which is measured explicitly by pinging from each machine to every other one. As the number of machines increase, calculating the \textit{RTT} becomes extremely expensive and may outweigh the benefits of exploiting network proximity. 

To overcome the aforementioned problem, one could estimate, instead of measuring exactly, the \textit{RTT} with less computationally expensive methods. There has been extensive research on \textit{RTT} estimation for \textit{peer-to-peer (P2P)} networks\cite{rtt_survey}. Most of the methods proposed suffer from the constraint that estimation is calculated on a single machine, therefore introducing a central point of failure. This is highly unsuited for distributed system, where a decentralized approach should be used. One such attractive approach is the \textit{Vivaldi} coordinate system\cite{vivaldi}, which is a simple and lightweight algorithm that assigns synthetic coordinates to hosts such that the distance between the coordinates of two hosts accurately predicts the communication latency between them. The algorithm is completely decentralized (i.e. the same piece of code runs on every host) and experiments show that it achieves a median relative error of 11\%, where the error is characterised by the squared-error function:

\[ E =  \sum_i \sum_j (L_{ij}-||x_i - x_j||)^2  \]

where $L_{ij}$ is the actual RTT between nodes $i$ and $j$ and $||x_i - x_j||$ is the euclidean distance between their coordinates.

\thesissubsection{Advanced fault-tolerance}

An aspect that \textit{RHEA} is far behind from most of its competing frameworks is fault-tolerance. Although there is a minimal control on \textit{back-pressure}, available through the small provided set of such operators, still there are no advanced methods for specifying behaviour for graceful error-recovery.

The above is essential for large machine clusters, in which systems it is certain that host failures and other faults will be a common occurrence. The functional nature of the dataflow model enables fault-tolerance, in addition to parallelism, due to the fact that a node can be moved to another machine for execution, while preserving the original semantics.

The extension proposed is to first provide low-level functionality for moving nodes across the network at runtime, and then use that to design high-level error recovery mechanisms. The issue confronted here is that, at the current state of the system, everything is configured statically before evaluation. To enable runtime configuration, it is mandatory to refactor major internal components, as previously noted.

This contribution path can draw heavy influence from recent research on fault-tolerance for stream processing engines\cite{borealis,dstreams,wide_area}. These provide efficient models for availability and data recovery/consistency, by using data replication and even parallel recovery of lost state across the cluster.

\thesissubsection{Integration with other technologies}

An issue that should not be neglected is interoperability with other dataflow frameworks mentioned throughout this thesis. Although the usage of \textit{RSS} partly aids that cause, not all frameworks for the JVM support it, especially older ones, and is practically useless concerning non-JVM frameworks.

A nice idea would be an \textit{ExportStrategy} that provides a one-to-one mapping between different dataflow representations. For instance, the \textit{NodeRedExportStrategy} would export a single JSON file ready to be imported into \textit{Node-RED} and deployed immediately. An issue that quickly arises is that of expressibility, meaning that the target platform should be at least as expressible as \textit{RHEA}. This can be solved by providing a mechanism/DSL to specify restricted views of the Stream class, which allow for a subset of the original operation set. 

\thesissubsection{Visual language}

The dataflow programming model also provides a very intuitive graphical representation to the structure of the software system being implemented. Thus, a helpful tool would be a graphical environment, where graph construction can be achieved through the user interface and delegate only the stream declaration part to a text editor. Another useful functionality would be clustering together sub-graphs by zooming out to provide clarity in complex systems.

Another useful utility is to provide visual debugging support, so as to be able to monitor values and errors going through the streams real-time or by playing back the recorded actions. Moreover, if dynamic reconfiguration is supported, the visual debugger could display where each node is being executed at each moment in time and other relative information.

\thesissubsection{Stream reasoning}	

A very helpful extension to any dataflow framework is the ability to reason about, in formal logic, the ever-changing streams of data. This creates the need for a new formal logic that is able to capture this flowing notion, which has also troubled the new \textit{Semantic Web} field\cite{streaming_world}. Fortunately, various sound and efficient logic formalisms have been conceived recently\cite{pdt_logic,asp}.

Stream reasoning has also been researched in the robotics domain\cite{robot_reasoning}, which led to the development of a stream reasoning framework for \textit{ROS} called \textit{DyKnown}\cite{stream_reasoning}. Integrating \textit{DyKnow} with \textit{RHEA}, as they both can support ROS, would certainly be a meaningful contribution. Figure \ref{fig:dyknow} shows the general architecture of the \textit{DyKnow} framework.

\myimage{dyknow}{0.5}{DyKnow architecture}

\thesissection{Conclusions}

The framework described in this thesis was designed with extensibility in mind, aiming to act as a fundamental basis, onto which various domain-specific libraries or DSLs will rely in the future. To that end, a constant effort to generalize and make components as abstract as possible was made. 

The set of operators aided expressibility, making it possible to specify any dataflow graph in a concise and readable manner. This disallowed optimizations suitable for less expressive models (e.g. \textit{Map-Reduce}), but recent research has shown that general dataflow topologies have optimization opportunities that are yet to be found\cite{blackbox}. A minimal optimization stage has been implemented, which paves the path to more advanced optimization techniques, such as those used in \textit{Naiad}\cite{naiad} and \textit{Stratosphere}\cite{static_analysis}.

Figure \ref{fig:core} illustrates all the pluggable components of the framework around the core, which are normally deployed in separate libraries.

\mydiag{core}{The \textit{RHEA} ecosystem}

The applications demonstrated the framework's ability to provide a higher level of abstraction, where the language only specifies how different components coordinate, without knowledge of the implementation details. This is exactly what \textit{Ziria} accomplishes in the domain of wireless systems programming\cite{ziria}. The driving force for both frameworks (i.e. \textit{RHEA} and \textit{Ziria}) is that some specific domains have fixated their methods on low-level programming, whereas more satisfactory paradigms can solve many shortcomings.

This is a general notion in computer science, owning its existence to the fact that the problems we are facing are getting increasingly more complex, while resources meet certain realistic bounds, and therefore a higher abstraction layer is mandatory for maintaining readability, efficiency and expressibility.

\begin{thesisabbreviations}
A table of all abbreviations used throughout the thesis follows.

\begin{tabularx}{\textwidth}{|X|X|}
  \hline
  FRP & Functional Reactive Programming \\
  JVM & Java Virtual Machine \\
  NCSR & National Centre for Scientific Research \\
  ROS & Robot Operating System \\
  IoT & Internet of Things \\
  CPU & Central Processing Unit \\
  TCP & Transmission Control Protocol \\
  PubSub & Publish/Subscribe \\
  OOP & Object-oriented Programming \\
  UML & Unified Modelling Language \\
  GPU & Graphics Processing Unit \\
  DSL & Domain-specific Language \\
  RSS & Reactive Streams Standard \\
  API & Application Programming Interface \\
  MPI & Message Passsing Inteface \\
  JSON & JavaScript Object Notation \\
  RTT & Round-Trip Time \\ 
  P2P & Peer-To-Peer \\
  AOP & Aspect-Oriented Programming \\
  GUI & Graphical User Interface \\
  WLAN & Wireless Local Area Network \\
  SDR & Software-defined Radio \\
  \hline
\end{tabularx}

\end{thesisabbreviations}

\newpage
\bibliographystyle{ieeetr}
\bibliography{thesis}{}

\thesissection*{Appendix: Complete set of stream operators}

This section displays the set of primitive operators, from which all the available stream operators are derived. Type information is not shown for the sake of readability, but all operations are type-safe.

In the marble diagrams on the right, circles represent \textit{onNext} notifications, green bars \textit{onComplete} and red x signals an \textit{onError}.

\thesissubsection*{Creation}
The following operators act as source nodes in the dataflow graph.
\begin{description}
\myitem{from}{(Iterable \textbf{i})}{none}{\textbf{i} as a stream}
\myitemm{fromSource}{(Source \textbf{s})}{none}{the values emitted by \textbf{s}}
\myitem{interval}{(TimeInterval \textbf{t})}{none}{the natural numbers emitted every \textbf{t}}
\myitem{empty}{~}{none}{an empty stream}
\myitem{never}{~}{none}{a stream that emits no notification}
\myitem{repeat}{(int \textbf{n})}{single}{repeats the values of the input stream \textbf{n} times, or infinitely if $\textbf{n} < 0$}
\myitemmNospace{defer}{($\textbf{f}:() \to Stream$)}{none}{the stream generated by the given stream factory \textbf{f}}	
\end{description}

\thesissubsection*{Combining}
The following operators combine multiple streams to produce another one.
\begin{description}
\myitem{merge}{~}{many}{merges the input streams and completes as soon as any of them completes}
\myitem{concat}{~}{many}{concatenates the input streams in the given order}
\myitemNospace{zip}{($\textbf{f}: A1...An \to B$)}{many}{zips the input streams with the given function \textbf{f}}
\end{description}

\thesissubsection*{Filtering}
The following operators filter the values emitted by another stream.
\begin{description}
\myitem{filter}{($\textbf{f}: A \to Boolean$)}{single}{emits only values $i$ of the input stream, where $f(i) = true$}
\myitemm{filterMap}
{(\textbf{f}: A $\to$ B, \textbf{g}: B $\to$ Boolean)}{single}{emits only values $f(i)$ of the input stream the, where $(f \circ g)(i) = true$}
\myitem{distinct}{~}{single}{removes all duplicate values of the input stream}
\myitem{take}{(int \textbf{n})}{single}{extracts the first (last) \textbf{n} values of the input stream, if $\textbf{n} > 0 (< 0)$}
\myitemNospace{skip}{(int \textbf{n})}{single}{skips the first (last) \textbf{n} values of the input stream, if $\textbf{n} > 0 (< 0)$}
\end{description}

\thesissubsection*{Conditional}
The following operators behave depending on some conditions on their input stream
\begin{description}
\myitem{amb}{~}{many}{emits the values of one its input streams, whichever emits a value or terminates first}
\myitem{exists}{($\textbf{f}: A \to Boolean$)}{single}{returns True, if the input stream contains a value i, where $f(i) = true$ and False otherwise}
\myitemm{takeUntil}{(Stream \textbf{s})}{single}{extracts values of the input stream, until stream \textbf{s} emits a value}
\myitemm{skipUntil}{(Stream \textbf{s})}{single}{skips values of the input stream, until stream \textbf{s} emits a value}
\myitem{takeWhile}{($\textbf{f}: A \to Boolean$)}{single}{extracts values of the input stream until a value i is emitted, where $f(i) = false$}
\myitemNospace{skipWhile}{($\textbf{f}: A \to Boolean$)}{single}{skips values of the input stream until a value i is emitted, where $f(i) = false$}
\end{description}

\thesissubsection*{Transformational}
The following operators transform their input stream
\begin{description}
\myitem{map}{($\textbf{f}: A \to B$)}{single}{transforms the input stream by applying function \textbf{f} to every value emitted}
\myitem{scan}{(B seed, $\textbf{f}: B \times A \to B$)}{single}{transforms the input stream by sequentially applying function \textbf{f} to every value emitted  and emitting each result along the way}
\myitem{buffer}{(int \textbf{n})}{single}{packs together every \textbf{n} values of the input stream into a single List item}
\myitemmNospace{buffer}{(TimeInterval \textbf{t})}{single}{packs together values of the input stream emitted every \textbf{t} into a single List item}
\end{description}

\thesissubsection*{Feedback}
This operator enables cycles in the dataflow graph.
\begin{description}
\myitemNospace{loop}{($\textbf{f}: Stream \to Stream$)}{single}{attaches a sub-graph to the input stream's output, whose result acts as feedback to the attachment point}
\end{description}

\thesissubsection*{Error-handling}
The following operators are a mean to handle errors.
\begin{description}

\myitemm{onErrorResume}{(Stream \textbf{s})}{single}{mirrors the input stream, but instead of emitting an \textit{onError} Notification when an error occurs, continues emitting values of the given stream \textbf{s}}
\myitem{onErrorReturn}{($\textbf{f}: Throwable \to A$)}{single}{mirrors the input stream, but instead of emitting an \textit{onError} Notification when an error e occurs, emits the value $f(e)$ followed by a \textit{onComplete} Notification}
\myitemmNospace{retry}{(int \textbf{n})}{single}{mirrors the input stream, but instead of emitting an \textit{onError} Notification when an error occurs, resubscribes to it \textbf{n} times if $n > 0$, infinitely otherwise}
\end{description}

\thesissubsection*{Backpressure}
The following operators specify how a node behaves when the requests are too intense to handle, computationally or memory-wise. \textit{Backpressure} is the mechanism that handles fast publishers that interact with slow subscribers.
\begin{description}
\myitemm{onBackpressureBuffer}{~}{single}{buffers values that cannot be handled by the subscriber to emit them later on}
\myitemm{onBackpressureDrop}{~}{single}{drops values that cannot be handled by the subscriber, instead of emitting them}
\myitemm{onBackpressureLatest}{~}{single}{drops values that cannot be handled by the subscriber and always buffers the last one, instead of emitting them}
\myitem{sample}{(TimeInterval \textbf{t})}{single}{emits only the most-recent emitted value from the input stream within intervals of \textbf{t}}
\myitemmNospace{timeout}{(TimeInteval \textbf{t})}{single}{mirros the input stream, but emits \textit{onError} if there is no emission within windows of \textbf{t}}
\end{description}

\thesissubsection*{Utility}
The following operators provide some helpful utilities.
\begin{description}
\myitemm{doOnNext}{(Action \textbf{a})}{single}{execute Action \textbf{a} whenever onNext(Complete/Error) is called}
\myitemm{cache}{~}{single}{caches values emitted by the input stream for future subscribers}
\myitem{delay}{(TimeInterval \textbf{t})}{single}{emits the values of the input stream shifted forward in time by \textbf{t}}
\myitem{materialize}{~}{single}{wraps all values of input stream as Notifications}
\myitemNospace{dematerialize}{~}{single}{reverses the effect of \textbf{materialize}}
\end{description}

All other operators can be produced by combining the above primitive ones \\
(e.g. $flatMap \equiv map \circ merge$).

\end{document}
